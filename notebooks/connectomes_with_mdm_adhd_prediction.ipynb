{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLXNVhxsy3k5"
      },
      "source": [
        "# Connectomes Data and Modeling Techniques\n",
        "\n",
        "### Techniques covered in this Notebook\n",
        "- Preprocessing the functional connectome data\n",
        "- RiemannianMinimumDistanceToMean classification algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RN_PEO_oy3k7"
      },
      "source": [
        "## Functional Connectomes\n",
        "\n",
        "A **functional connectome** refers to the theoretical concept of the brain's functional connections, which describes how different brain regions interact and communicate with each other.\n",
        "\n",
        "**Functional connectome data**, on the other hand, is the actual data that represents these connections, typically obtained through neuroimaging techniques such as functional MRI. This data provides a quantitative measure of the synchronized activity between brain regions, allowing researchers to study and analyze the functional connectome.\n",
        "\n",
        "This data is crucial in ADHD research, as it can help us understand how brain connectivity patterns differ between individuals with ADHD and those without. By analyzing these patterns, we can identify potential biomarkers for ADHD and develop more accurate diagnostic tools.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ys8kgcdFy3k8"
      },
      "source": [
        "## The 2025 Datathon Functional Connectome Data\n",
        "\n",
        "The dataset correponds to the Functional Connectivity Networks (FCN) extracted from resting-state fMRIs of **1213 patients at 200 Regions Of Interest (ROIs)**. Patients are separated in two classes: ADHD and control. The goal will be to classify them. (You can also use these techniques to classify the sex of the patients.)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KETmRoeTy3k9"
      },
      "source": [
        "## Functional Connectome Data and SPD Matrices\n",
        "\n",
        "Functional connectome data is often approximated as a Symmetric Positive Definite (SPD) matrix. However, in reality, functional connectome data may not always be perfectly SPD."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoObavSgy3k9"
      },
      "source": [
        "# Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIPUb3SMz6Er",
        "outputId": "daf370cd-3dce-4d7b-f4b8-dbdd21406f7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: geomstats in /usr/local/lib/python3.11/dist-packages (2.8.0)\n",
            "Requirement already satisfied: joblib>=0.17.0 in /usr/local/lib/python3.11/dist-packages (from geomstats) (1.4.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.4 in /usr/local/lib/python3.11/dist-packages (from geomstats) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.11/dist-packages (from geomstats) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.11/dist-packages (from geomstats) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.11/dist-packages (from geomstats) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from geomstats) (1.14.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->geomstats) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->geomstats) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->geomstats) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->geomstats) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->geomstats) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->geomstats) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->geomstats) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->geomstats) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->geomstats) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->geomstats) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.1->geomstats) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.4->geomstats) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install geomstats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDyCZMFwzCVq",
        "outputId": "775a9f92-ba65-4700-8475-b57d4bdd3aca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#Mount Google Drive (only needed when run on Colab)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-08T13:10:07.19468Z",
          "iopub.status.busy": "2025-03-08T13:10:07.194397Z",
          "iopub.status.idle": "2025-03-08T13:10:24.977705Z",
          "shell.execute_reply": "2025-03-08T13:10:24.976595Z",
          "shell.execute_reply.started": "2025-03-08T13:10:07.194656Z"
        },
        "id": "k0jR9u8Ry3k9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "import openpyxl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import geomstats.datasets.utils as data_utils\n",
        "import geomstats.backend as gs\n",
        "from geomstats.geometry.skew_symmetric_matrices import SkewSymmetricMatrices\n",
        "import time\n",
        "\n",
        "# Start time measurement:\n",
        "start_time = time.time()\n",
        "\n",
        "# Read in the data (update to your root folder)\n",
        "df_soln = pd.read_excel(\"/content/drive/MyDrive/WIDS_2025/TRAIN_NEW/TRAINING_SOLUTIONS.xlsx\")\n",
        "df_conn = pd.read_csv(\"/content/drive/MyDrive/WIDS_2025/TRAIN_NEW/TRAIN_FUNCTIONAL_CONNECTOME_MATRICES_new_36P_Pearson.csv\")\n",
        "df_conn_test = pd.read_csv(\"/content/drive/MyDrive/WIDS_2025/TEST/TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv\")\n",
        "\n",
        "# Extract the ADHD solutions and sort the data by participant_id\n",
        "df_soln_adhd = df_soln[['participant_id', 'ADHD_Outcome']].sort_values('participant_id')\n",
        "df_conn = df_conn.sort_values('participant_id')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jm0-sF--y3k-"
      },
      "source": [
        "### Reshape the connectome data into symmetric matrices\n",
        "\n",
        "We are given the upper half of the connectome matrices as vectors, which represent the functional connections between different brain regions. However, to analyze and process this data using Riemannian geometry-based methods, we need to reshape it into symmetric matrices.\n",
        "\n",
        "By reshaping the upper half vectors into symmetric matrices, we can reconstruct the full matrix, which is a more natural representation of the brain's functional connectivity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-08T13:10:24.980014Z",
          "iopub.status.busy": "2025-03-08T13:10:24.979609Z",
          "iopub.status.idle": "2025-03-08T13:10:24.986477Z",
          "shell.execute_reply": "2025-03-08T13:10:24.985391Z",
          "shell.execute_reply.started": "2025-03-08T13:10:24.979973Z"
        },
        "id": "0ecCoKXuy3k-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Define the load_connectomes function\n",
        "def load_connectomes(df_conn, df_soln_adhd, as_vectors=False):\n",
        "    \"\"\"\n",
        "    Load brain connectome data and ADHD labels, returning symmetric matrices with ones on the diagonal.\n",
        "    \"\"\"\n",
        "\n",
        "    patient_id = gs.array(df_conn['participant_id'])\n",
        "    data = gs.array(df_conn.drop('participant_id', axis=1))\n",
        "    target = gs.array(df_soln_adhd['ADHD_Outcome'])\n",
        "\n",
        "    if as_vectors:\n",
        "        return data, patient_id, target\n",
        "    mat = SkewSymmetricMatrices(200).matrix_representation(data)\n",
        "    mat = gs.eye(200) - gs.transpose(gs.tril(mat), (0, 2, 1))\n",
        "    mat = 1.0 / 2.0 * (mat + gs.transpose(mat, (0, 2, 1)))\n",
        "\n",
        "    return mat, patient_id, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-08T13:10:24.987809Z",
          "iopub.status.busy": "2025-03-08T13:10:24.987449Z",
          "iopub.status.idle": "2025-03-08T13:23:10.265817Z",
          "shell.execute_reply": "2025-03-08T13:23:10.264773Z",
          "shell.execute_reply.started": "2025-03-08T13:10:24.987778Z"
        },
        "id": "hkhezbuyy3k-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Call the load_connectomes function\n",
        "data, patient_id, labels = load_connectomes(df_conn, df_soln_adhd)\n",
        "\n",
        "# Print the results\n",
        "print(f\"There are {len(data)} connectomes: {sum(labels==0)} non-ADHD and {sum(labels==1)} ADHD patients.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-08T13:23:10.268782Z",
          "iopub.status.busy": "2025-03-08T13:23:10.26833Z",
          "iopub.status.idle": "2025-03-08T13:23:10.276249Z",
          "shell.execute_reply": "2025-03-08T13:23:10.275359Z",
          "shell.execute_reply.started": "2025-03-08T13:23:10.268748Z"
        },
        "id": "ptEHKC1Fy3k-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iy4b3Fkoy3k-"
      },
      "source": [
        "We now have 200 x 200 matrices for each of the 1213 patients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXVsypwCy3k-"
      },
      "source": [
        "## Checking for SPD Manifold Membership\n",
        "\n",
        "Check if the connectome data lies on the Symmetric Positive Definite (SPD) manifold. We use the SPDMatrices class from the geomstats library to check for SPD property."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-08T13:23:10.278075Z",
          "iopub.status.busy": "2025-03-08T13:23:10.277744Z",
          "iopub.status.idle": "2025-03-08T13:23:11.566339Z",
          "shell.execute_reply": "2025-03-08T13:23:11.565366Z",
          "shell.execute_reply.started": "2025-03-08T13:23:10.278032Z"
        },
        "id": "MJt5IfaZy3k-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from geomstats.geometry.spd_matrices import SPDMatrices\n",
        "\n",
        "manifold = SPDMatrices(200, equip=False)\n",
        "print(gs.all(manifold.belongs(data)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-08T13:23:11.56766Z",
          "iopub.status.busy": "2025-03-08T13:23:11.567302Z",
          "iopub.status.idle": "2025-03-08T13:23:12.788697Z",
          "shell.execute_reply": "2025-03-08T13:23:12.787704Z",
          "shell.execute_reply.started": "2025-03-08T13:23:11.567623Z"
        },
        "id": "k5P6Lsqry3k_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Count the number of connectomes that do not lie on the SPD manifold\n",
        "\n",
        "count_false = np.sum(~(manifold.belongs(data)))\n",
        "print(\"Count of False:\", count_false)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1LafXp7y3k_"
      },
      "source": [
        "### Ensuring SPD Property\n",
        "\n",
        "To ensure the data is Symmetric Positive Definite (SPD), we can add a small diagonal matrix to the original data. This approach modifies the data minimally while guaranteeing the SPD property. The small diagonal matrix is added to each 2D slice of the 3D matrix, but the correction is only non-zero for the slices that are not SPD."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-08T13:23:12.789949Z",
          "iopub.status.busy": "2025-03-08T13:23:12.789672Z",
          "iopub.status.idle": "2025-03-08T13:23:28.378684Z",
          "shell.execute_reply": "2025-03-08T13:23:28.37772Z",
          "shell.execute_reply.started": "2025-03-08T13:23:12.789926Z"
        },
        "id": "IPIxWx1ry3k_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Function to add a diagonal matrix to a 2D matrix\n",
        "def add_diagonal_correction(matrix):\n",
        "    eigenvalues = np.linalg.eigvals(matrix)\n",
        "    min_eigenvalue = np.min(eigenvalues)\n",
        "\n",
        "    if min_eigenvalue < 0:\n",
        "        correction = -min_eigenvalue + 1e-6\n",
        "        correction_matrix = correction * np.eye(matrix.shape[0])\n",
        "        return matrix + correction_matrix\n",
        "    else:\n",
        "        return matrix\n",
        "\n",
        "# Apply the correction to each 2D slice of the 3D matrix\n",
        "data_corrected = np.array([add_diagonal_correction(slice) for slice in data])\n",
        "\n",
        "print(\"Original Matrix shape:\", data.shape)\n",
        "print(\"Corrected Matrix shape:\", data_corrected.shape)\n",
        "\n",
        "print(gs.all(manifold.belongs(data_corrected)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ne2cF5zly3k_"
      },
      "source": [
        "#### Counting differences in original data and corrected data\n",
        "\n",
        "We expect the count of differences to be 12 X 200 = 2400, since we added a correction to 12 connectomes, each with 200 features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-08T13:23:28.37989Z",
          "iopub.status.busy": "2025-03-08T13:23:28.379597Z",
          "iopub.status.idle": "2025-03-08T13:23:28.630836Z",
          "shell.execute_reply": "2025-03-08T13:23:28.629822Z",
          "shell.execute_reply.started": "2025-03-08T13:23:28.379865Z"
        },
        "id": "wAgOfWAjy3k_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def count_differences(array1, array2, tolerance=1e-6):\n",
        "    \"\"\"\n",
        "    This function compares two 3D arrays and returns the count of differences.\n",
        "    \"\"\"\n",
        "    if array1.shape != array2.shape:\n",
        "        raise ValueError(\"Arrays must be of the same shape\")\n",
        "\n",
        "    differences = np.greater(np.abs(array1 - array2), tolerance)\n",
        "    count = np.sum(differences)\n",
        "\n",
        "    return count\n",
        "\n",
        "print(count_differences(data, data_corrected))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqXXdGVKy3k_"
      },
      "source": [
        "# Classification algorithm: RiemannianMinimumDistanceToMean\n",
        "\n",
        "**Reference** Geometric Approaches for Processing Brain Connectomes video: https://www.youtube.com/watch?v=vtHBOBOcn6E\n",
        "\n",
        "The RiemannianMinimumDistanceToMean algorithm is based on Riemannian geometry, which is a mathematical framework that allows us to analyze and process data on curved spaces, such as the space of symmetric positive definite (SPD) matrices. This is particularly useful for brain connectome data, which can be represented as SPD matrices. This algorithm calculates the Riemannian distance between each connectome and the mean of each class, and assigns the connectome to the class with the smallest distance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6CP-EnYy3lA"
      },
      "source": [
        "### Define the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-08T13:23:28.632023Z",
          "iopub.status.busy": "2025-03-08T13:23:28.63175Z",
          "iopub.status.idle": "2025-03-08T13:23:28.977408Z",
          "shell.execute_reply": "2025-03-08T13:23:28.976482Z",
          "shell.execute_reply.started": "2025-03-08T13:23:28.631999Z"
        },
        "id": "o_dvFEXyy3lA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from geomstats.learning.mdm import RiemannianMinimumDistanceToMean\n",
        "\n",
        "spd_manifold = SPDMatrices(n=200, equip=True)\n",
        "mdm = RiemannianMinimumDistanceToMean(space=spd_manifold)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqOp5aqoy3lA"
      },
      "source": [
        "### Split data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-08T13:23:28.978658Z",
          "iopub.status.busy": "2025-03-08T13:23:28.9784Z",
          "iopub.status.idle": "2025-03-08T13:23:29.125337Z",
          "shell.execute_reply": "2025-03-08T13:23:29.124431Z",
          "shell.execute_reply.started": "2025-03-08T13:23:28.978636Z"
        },
        "id": "nwNdVHIfy3lA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = data_corrected; y = labels\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=47)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXU213-Wy3lA"
      },
      "source": [
        "### Print data statistics\n",
        "\n",
        "We examine the class distribution in the full dataset, as well as the train and test sets, to ensure that they are similar and representative of the overall data. This is crucial for training a reliable model, as a skewed class distribution can lead to biased results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-08T13:23:29.126645Z",
          "iopub.status.busy": "2025-03-08T13:23:29.126297Z",
          "iopub.status.idle": "2025-03-08T13:23:29.150175Z",
          "shell.execute_reply": "2025-03-08T13:23:29.149093Z",
          "shell.execute_reply.started": "2025-03-08T13:23:29.12661Z"
        },
        "id": "Emvo_X_6y3lA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(f\"The dataset has {len(X)} connectomes.\")\n",
        "print(f\"The train set has {len(X_train)} connectomes and has size {X_train.shape}.\")\n",
        "print(f\"The test set has {len(X_test)} connectomes and has size {X_test.shape}.\")\n",
        "\n",
        "print(\"Full dataset class distribution:\")\n",
        "print(pd.Series(y).value_counts(normalize=True) * 100)\n",
        "\n",
        "print(\"\\nTrain dataset class distribution:\")\n",
        "print(pd.Series(y_train).value_counts(normalize=True) * 100)\n",
        "\n",
        "print(\"\\nTest dataset class distribution:\")\n",
        "print(pd.Series(y_test).value_counts(normalize=True) * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpoGuex6y3lA"
      },
      "source": [
        "### Train and Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-08T13:23:29.15387Z",
          "iopub.status.busy": "2025-03-08T13:23:29.153572Z",
          "iopub.status.idle": "2025-03-08T13:23:48.756094Z",
          "shell.execute_reply": "2025-03-08T13:23:48.755182Z",
          "shell.execute_reply.started": "2025-03-08T13:23:29.153841Z"
        },
        "id": "tDDqxkjsy3lA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "mdm.fit(X_train, y_train)\n",
        "print(mdm.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-08T15:43:31.753156Z",
          "iopub.status.busy": "2025-03-08T15:43:31.752821Z",
          "iopub.status.idle": "2025-03-08T15:43:39.867822Z",
          "shell.execute_reply": "2025-03-08T15:43:39.866933Z",
          "shell.execute_reply.started": "2025-03-08T15:43:31.75313Z"
        },
        "id": "Vn_9D8Hly3lA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSbIzrNQy3lA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "y_pred = mdm.predict(X_test)\n",
        "print(\"F1 score:\", f1_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSJc2lxnC9sT"
      },
      "outputs": [],
      "source": [
        "y_train_pred = mdm.predict(X)\n",
        "print(\"F1 score:\", f1_score(y, y_train_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50JY3Vbu1aRw"
      },
      "outputs": [],
      "source": [
        "from scipy.special import expit\n",
        "y_train_probabilities = expit(y_train_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_SFjApUFO4u"
      },
      "outputs": [],
      "source": [
        "patient_id_np = np.array(patient_id)\n",
        "print('Patient id np shape: ', patient_id_np.shape)\n",
        "print('Y train probs shape: ', y_train_probabilities.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCJ5QeY74a3h"
      },
      "outputs": [],
      "source": [
        "y_train_probabilities_df = pd.DataFrame({'participant_id': patient_id_np, 'ADHD_pred': y_train_pred, 'ADHD_prob': y_train_probabilities})\n",
        "y_train_probabilities_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQmunvAf1aYf"
      },
      "outputs": [],
      "source": [
        "y_train_probabilities_df.to_csv('/content/drive/MyDrive/WIDS_2025/Output/mdm_train_pred_prob_adhd.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64YTgcOoy3lA"
      },
      "source": [
        "## Prediction on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cG6WunK26WKH"
      },
      "outputs": [],
      "source": [
        "def load_connectomes_test(df_conn):\n",
        "\n",
        "    \"\"\"\n",
        "    Load brain connectome data, returning symmetric matrices with ones on the diagonal.\n",
        "    \"\"\"\n",
        "\n",
        "    patient_id = gs.array(df_conn['participant_id'])\n",
        "    data = gs.array(df_conn.drop('participant_id', axis=1))\n",
        "\n",
        "    mat = SkewSymmetricMatrices(200).matrix_representation(data)\n",
        "    mat = gs.eye(200) - gs.transpose(gs.tril(mat), (0, 2, 1))\n",
        "    mat = 1.0 / 2.0 * (mat + gs.transpose(mat, (0, 2, 1)))\n",
        "\n",
        "    return mat, patient_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmVkgtfXy3lB"
      },
      "outputs": [],
      "source": [
        "data_test, patient_id_test = load_connectomes_test(df_conn_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORJ1fAtfy3lB"
      },
      "outputs": [],
      "source": [
        "data_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9uJPT5vy3lB"
      },
      "outputs": [],
      "source": [
        "manifold = SPDMatrices(200, equip=False)\n",
        "print(gs.all(manifold.belongs(data_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klL2wJ8Ey3lB"
      },
      "outputs": [],
      "source": [
        "# Count the number of connectomes that do not lie on the SPD manifold\n",
        "\n",
        "count_false = np.sum(~(manifold.belongs(data_test)))\n",
        "print(\"Count of False:\", count_false)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVDWG_E7y3lB"
      },
      "outputs": [],
      "source": [
        "# Apply the correction to each 2D slice of the 3D matrix\n",
        "data_test_corrected = np.array([add_diagonal_correction(slice) for slice in data_test])\n",
        "\n",
        "print(\"Original Matrix shape:\", data_test.shape)\n",
        "print(\"Corrected Matrix shape:\", data_test_corrected.shape)\n",
        "\n",
        "print(gs.all(manifold.belongs(data_test_corrected)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3RGk3lfy3lB"
      },
      "outputs": [],
      "source": [
        "# Count differences between original and corrected test data:\n",
        "print(count_differences(data_test, data_test_corrected))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2GzaQAey3lF"
      },
      "outputs": [],
      "source": [
        "y_pred_test = mdm.predict(data_test_corrected)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPe_T0gy13x6"
      },
      "outputs": [],
      "source": [
        "y_pred_test_probabilities = expit(y_pred_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCOeiP31FWwb"
      },
      "outputs": [],
      "source": [
        "patient_id_test_np = np.array(patient_id_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUNgo6cH132f"
      },
      "outputs": [],
      "source": [
        "y_pred_test_probabilities_df = pd.DataFrame({'participant_id': patient_id_test_np, 'ADHD_pred': y_pred_test, 'ADHD_prob': y_pred_test_probabilities})\n",
        "y_pred_test_probabilities_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twksmtH246b0"
      },
      "outputs": [],
      "source": [
        "y_pred_test_probabilities_df.to_csv('/content/drive/MyDrive/WIDS_2025/Output/mdm_test_pred_prob_adhd.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9K0OeSbty3lF"
      },
      "outputs": [],
      "source": [
        "submission_mdm = pd.DataFrame({'participant_id': patient_id_test_np, 'ADHD_pred': y_pred_test})\n",
        "submission_mdm.to_csv('/content/drive/MyDrive/WIDS_2025/Output/submission_mdm_adhd.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyuv1UWV1AQq"
      },
      "outputs": [],
      "source": [
        "# Print runtime\n",
        "end_time = time.time()\n",
        "runtime = round((end_time - start_time)/60, 1)\n",
        "print('Runtime of ADHD prediction with MDM: ', runtime, 'minutes')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "databundleVersionId": 11498594,
          "sourceId": 90566,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30918,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
